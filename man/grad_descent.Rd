% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/utils.R
\name{grad_descent}
\alias{grad_descent}
\title{Gradient descent optimizer with numerical gradients}
\usage{
grad_descent(
  f,
  x0,
  sup = function(x) TRUE,
  lr = 0.01,
  eps = 1e-08,
  max_iter = 10000L,
  debug = FALSE,
  h = 1e-06
)
}
\arguments{
\item{f}{Function to minimize. Takes a vector and returns a scalar.}

\item{x0}{Initial parameter values.}

\item{sup}{Support function. Returns TRUE if parameters are valid.}

\item{lr}{Learning rate (step size).}

\item{eps}{Convergence tolerance for gradient norm.}

\item{max_iter}{Maximum number of iterations.}

\item{debug}{If TRUE, print debugging information.}

\item{h}{Step size for numerical gradient approximation.}
}
\value{
A list with components:
\item{param}{Final parameter values}
\item{converged}{TRUE if converged within max_iter}
\item{iter}{Number of iterations performed}
\item{value}{Final function value}
}
\description{
Minimizes a function \code{f} using gradient descent with numerical gradient
approximation. Supports constraints via a support function.
}
\keyword{internal}
