%% ============================================================================
\section{Simulation Studies}
\label{sec:simulations}
%% ============================================================================

We present simulation studies to (1) validate MLE performance under the
C1-C2-C3 Bernoulli masking model, (2) quantify the bias from incorrectly
assuming C2 when masking is informative, and (3) investigate identifiability
issues arising from correlated candidate sets.

\subsection{Experimental Design}
\label{sec:sim-design}

\subsubsection{System Configuration}

We consider exponential series systems with $m = 3$ components and true rate
parameters:
\begin{equation}
    \vlambda^* = (\lambda_1^*, \lambda_2^*, \lambda_3^*) = (1.0, 1.5, 2.0).
\end{equation}
These values represent a system where component 3 has the highest failure rate
(and thus contributes most to system failures), while component 1 is most
reliable.

\subsubsection{Data Generation}

For each simulation replicate:
\begin{enumerate}
    \item Generate component failure times $T_{ij} \sim \text{Exp}(\lambda_j^*)$
        for $i = 1, \ldots, n$ and $j = 1, \ldots, m$.
    \item Compute system failure times $T_i = \min_j T_{ij}$ and identify
        failed components $K_i = \arg\min_j T_{ij}$.
    \item Apply right-censoring at time $\tau$ (chosen to achieve approximately
        20\% censoring) to obtain observed lifetimes $S_i = \min(T_i, \tau)$
        and indicators $\delta_i$.
    \item Generate candidate sets using the specified masking model.
\end{enumerate}

\subsubsection{Masking Models}

We examine three masking scenarios:
\begin{enumerate}
    \item \textbf{C1-C2-C3 (Baseline):} Bernoulli model with $p = 0.3$ for
        all non-failed components.
    \item \textbf{Informative masking (Rank-based):} Masking probabilities
        depend on component failure time ranks, parameterized by
        informativeness parameter $\alpha \in \{0, 1, 2, 5, 10\}$.
    \item \textbf{Correlated candidate sets:} Candidate set indicators have
        correlation $\rho \in \{0, 0.1, 0.3, 0.5, 0.6, 0.8, 0.9\}$.
\end{enumerate}

\subsubsection{Performance Metrics}

We evaluate:
\begin{itemize}
    \item \textbf{Bias:} $\text{Bias}(\hat{\lambda}_j) =
        \E[\hat{\lambda}_j] - \lambda_j^*$
    \item \textbf{Root mean squared error (RMSE):}
        $\text{RMSE}(\hat{\lambda}_j) = \sqrt{\E[(\hat{\lambda}_j - \lambda_j^*)^2]}$
    \item \textbf{Coverage probability:} Proportion of 95\% confidence
        intervals containing $\lambda_j^*$
    \item \textbf{RMSE ratio:} $\text{RMSE}_{\text{misspec}} /
        \text{RMSE}_{\text{correct}}$
\end{itemize}

\subsection{Study 1: MLE Performance Under Bernoulli Masking}
\label{sec:sim-kl}

We first validate MLE performance under the correctly specified C1-C2-C3
Bernoulli masking model across sample sizes $n \in \{50, 100, 200\}$ with
$B = 200$ Monte Carlo replicates.

\subsubsection{Results}

Table~\ref{tab:mle_performance} presents the estimation results.

\begin{table}[htbp]
\centering
\caption{Maximum Likelihood Estimation Performance by Sample Size}
\label{tab:mle_performance}
\begin{tabular}{cccccc}
\toprule
$n$ & Parameter & Bias & RMSE & Coverage & Mean CI Width \\
\midrule
50 & $\lambda_1$ & 0.017 & 0.477 & 0.920 & 1.727 \\
 & $\lambda_2$ & 0.007 & 0.511 & 0.935 & 1.952 \\
 & $\lambda_3$ & 0.085 & 0.557 & 0.945 & 2.197 \\
\midrule
100 & $\lambda_1$ & 0.016 & 0.318 & 0.935 & 1.175 \\
 & $\lambda_2$ & 0.055 & 0.390 & 0.935 & 1.385 \\
 & $\lambda_3$ & $-0.037$ & 0.366 & 0.950 & 1.519 \\
\midrule
200 & $\lambda_1$ & $-0.005$ & 0.201 & 0.935 & 0.825 \\
 & $\lambda_2$ & 0.008 & 0.262 & 0.965 & 0.965 \\
 & $\lambda_3$ & $-0.033$ & 0.258 & 0.955 & 1.066 \\
\bottomrule
\end{tabular}

\vspace{2pt}
\begin{minipage}{\textwidth}
\footnotesize
\textit{Notes.} Results based on 200 Monte Carlo replications. True parameters:
$\lambda_1 = 1.0$, $\lambda_2 = 1.5$, $\lambda_3 = 2.0$.
Bernoulli masking with $p = 0.3$, censoring proportion $\approx 20\%$.
\end{minipage}
\end{table}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.8\textwidth]{fig1_rmse_by_sample_size.pdf}
\caption{RMSE of MLE by sample size. All three component rate parameters show
decreasing RMSE as sample size increases, consistent with $\sqrt{n}$-convergence.}
\label{fig:rmse_sample_size}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.8\textwidth]{fig2_coverage_by_sample_size.pdf}
\caption{95\% confidence interval coverage probability by sample size. Coverage
is near the nominal 95\% level across all parameters and sample sizes, validating
the asymptotic normal approximation.}
\label{fig:coverage_sample_size}
\end{figure}

Key findings from Study 1:
\begin{enumerate}
    \item \textbf{Consistency:} Bias is small relative to RMSE at all sample
        sizes, indicating approximate unbiasedness.
    \item \textbf{Convergence:} RMSE decreases from approximately 0.5 at $n=50$
        to 0.2--0.3 at $n=200$, consistent with $\sqrt{n}$-rate convergence.
    \item \textbf{Coverage:} 95\% CI coverage ranges from 92.0\% to 96.5\%,
        close to the nominal level, validating the Fisher information-based
        standard errors.
    \item \textbf{Component effects:} Components with higher true rates
        ($\lambda_3 = 2.0$) have slightly larger absolute RMSE but similar
        relative performance.
\end{enumerate}

\subsection{Study 2: Misspecification Bias Analysis}
\label{sec:sim-bias}

We quantify the bias from incorrectly assuming C1-C2-C3 when masking is
actually informative. Data is generated with rank-based informative masking
(informativeness parameter $\alpha$), then analyzed using both the correct
model and the misspecified C2 model.

\subsubsection{Results}

Table~\ref{tab:misspecification_bias} compares bias under correct versus
misspecified models.

\begin{table}[htbp]
\centering
\caption{Bias Comparison: Correct vs Misspecified Model}
\label{tab:misspecification_bias}
\begin{tabular}{ccccc}
\toprule
$\alpha$ & Parameter & Bias (Correct) & Bias (Misspec.) & RMSE Ratio \\
\midrule
0 & $\lambda_1$ & $-0.129$ & $-0.001$ & 1.019 \\
  & $\lambda_2$ & 0.027 & 0.024 & 1.090 \\
  & $\lambda_3$ & 0.105 & $-0.020$ & 1.013 \\
\midrule
1 & $\lambda_1$ & $-0.136$ & $-0.095$ & 0.999 \\
  & $\lambda_2$ & $-0.009$ & $-0.004$ & 1.031 \\
  & $\lambda_3$ & 0.192 & 0.146 & 0.944 \\
\midrule
5 & $\lambda_1$ & $-0.129$ & $-0.127$ & 1.002 \\
  & $\lambda_2$ & $-0.005$ & 0.010 & 1.031 \\
  & $\lambda_3$ & 0.147 & 0.130 & 0.988 \\
\midrule
10 & $\lambda_1$ & $-0.153$ & $-0.152$ & 1.022 \\
   & $\lambda_2$ & 0.000 & 0.002 & 0.993 \\
   & $\lambda_3$ & 0.183 & 0.178 & 1.008 \\
\bottomrule
\end{tabular}

\vspace{2pt}
\begin{minipage}{\textwidth}
\footnotesize
\textit{Notes.} $\alpha = 0$ corresponds to non-informative masking (C2 satisfied).
As $\alpha$ increases, masking becomes more informative.
RMSE Ratio = RMSE(Misspecified) / RMSE(Correct); values $> 1$ indicate
efficiency loss.
\end{minipage}
\end{table}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.9\textwidth]{fig3_misspecification_bias.pdf}
\caption{Bias comparison between correct and misspecified models as masking
informativeness increases. The misspecified model (incorrectly assuming C2)
shows similar bias patterns to the correct model for moderate informativeness.}
\label{fig:misspec_bias}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.8\textwidth]{fig4_rmse_ratio.pdf}
\caption{RMSE ratio (misspecified/correct) by informativeness parameter. Values
near 1 indicate minimal efficiency loss from misspecification. The maximum
ratio of 1.09 suggests the C2 assumption is reasonably robust.}
\label{fig:rmse_ratio}
\end{figure}

Key findings from Study 2:
\begin{enumerate}
    \item \textbf{Moderate robustness:} The RMSE ratio stays between 0.94 and
        1.09 across all informativeness levels, indicating that misspecifying
        the masking model produces at most 9\% efficiency loss.
    \item \textbf{Bias similarity:} Surprisingly, bias under the misspecified
        model closely tracks bias under the correct model, suggesting the C2
        assumption is more robust than theoretical arguments might suggest.
    \item \textbf{Parameter-specific effects:} Component 3 ($\lambda_3$) shows
        consistently positive bias under both models, likely due to its higher
        failure rate making it more frequently the true cause of failure.
\end{enumerate}

\subsection{Study 3: Identifiability and Candidate Set Correlation}
\label{sec:sim-ident}

We investigate how correlation between candidate set indicators affects
identifiability by examining the Fisher Information Matrix (FIM) eigenvalues.

\subsubsection{Results}

Table~\ref{tab:identifiability} presents FIM analysis by correlation level.

\begin{table}[htbp]
\centering
\caption{Fisher Information Matrix Analysis by Candidate Set Correlation}
\label{tab:identifiability}
\begin{tabular}{ccc}
\toprule
$\rho$ & Smallest Eigenvalue & Condition Number \\
\midrule
0.0 & 12.23 & 2.18 \\
0.1 & 12.93 & 2.12 \\
0.3 & 14.17 & 2.01 \\
0.5 & 15.00 & 1.97 \\
0.6 & 15.12 & 1.91 \\
0.8 & 14.33 & 2.01 \\
0.9 & 13.88 & 2.04 \\
\bottomrule
\end{tabular}

\vspace{2pt}
\begin{minipage}{\textwidth}
\footnotesize
\textit{Notes.} $\rho$ measures correlation between candidate set indicators.
As $\rho \to 1$, components always co-occur in candidate sets, theoretically
leading to non-identifiability.
\end{minipage}
\end{table}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.8\textwidth]{fig5_fim_eigenvalue.pdf}
\caption{Smallest FIM eigenvalue versus candidate set correlation. The eigenvalue
remains bounded away from zero even at $\rho = 0.9$, indicating identifiability
is maintained in our simulation setup.}
\label{fig:fim_eigenvalue}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.8\textwidth]{fig6_rmse_by_correlation.pdf}
\caption{RMSE of MLE by candidate set correlation. Performance remains stable
across correlation levels, consistent with the FIM eigenvalue analysis.}
\label{fig:rmse_correlation}
\end{figure}

Key findings from Study 3:
\begin{enumerate}
    \item \textbf{Identifiability preserved:} The smallest FIM eigenvalue
        remains substantially positive (12--15) across all correlation levels,
        indicating parameters remain identifiable.
    \item \textbf{Condition number stable:} The condition number stays below 2.2,
        indicating a well-conditioned estimation problem.
    \item \textbf{Nonmonotonic pattern:} Interestingly, the smallest eigenvalue
        peaks around $\rho = 0.5$--$0.6$, suggesting moderate correlation may
        actually improve information content.
\end{enumerate}

\subsection{Study 4: C3 Misspecification Bias Analysis}
\label{sec:sim-c3}

We now quantify the bias from incorrectly assuming C1-C2-C3 when masking is
actually parameter-dependent (C3 violated). Data is generated with
power-weighted masking (\Cref{def:power-masking}) with varying
informativeness $\alpha$, then analyzed using both the correct model and the
misspecified C1-C2-C3 model. This study is motivated by the theoretical
result in \Cref{thm:misspec-C3}.

\subsubsection{Design}

Data is generated under the power-weighted masking model with
$\text{base\_p} = 0.5$ and $\alpha \in \{0, 0.5, 1, 2\}$, using $n = 200$
and $B = 200$ replications. Three comparisons are made:
\begin{description}
    \item[Scenario 6:] Relaxed C3 data analyzed with C1-C2-C3 model
        (misspecified).
    \item[Scenario 6b:] Relaxed C3 data analyzed with relaxed C3 model
        using known $\alpha$ (correctly specified).
    \item[Scenario 5:] C1-C2-C3 data analyzed with relaxed C3 model
        (overfitting check).
\end{description}

\subsubsection{Results}

Table~\ref{tab:c3_misspec_bias} compares bias under correct versus
misspecified models for C3 violations.

\begin{table}[htbp]
\centering
\caption{C3 Misspecification: Bias Comparison by Power Parameter $\alpha$}
\label{tab:c3_misspec_bias}
\begin{tabular}{ccccc}
\toprule
$\alpha$ & Parameter & Bias (Correct) & Bias (Misspec.) & RMSE Ratio \\
\midrule
0 & $\lambda_1$ & $-0.011$ & $-0.011$ & $1.000$ \\
  & $\lambda_2$ & $0.036$ & $0.036$ & $1.000$ \\
  & $\lambda_3$ & $0.029$ & $0.029$ & $1.000$ \\
\midrule
0.5 & $\lambda_1$ & $-0.762$ & $-0.264$ & $0.424$ \\
    & $\lambda_2$ & $0.195$ & $0.003$ & $0.801$ \\
    & $\lambda_3$ & $0.619$ & $0.314$ & $0.626$ \\
\midrule
1 & $\lambda_1$ & $-0.691$ & $-0.366$ & $0.574$ \\
  & $\lambda_2$ & $0.116$ & $-0.067$ & $1.077$ \\
  & $\lambda_3$ & $0.628$ & $0.486$ & $0.834$ \\
\midrule
2 & $\lambda_1$ & $-0.569$ & $-0.432$ & $0.788$ \\
  & $\lambda_2$ & $0.026$ & $-0.205$ & $1.850$ \\
  & $\lambda_3$ & $0.597$ & $0.691$ & $1.169$ \\
\bottomrule
\end{tabular}

\vspace{2pt}
\begin{minipage}{\textwidth}
\footnotesize
\textit{Notes.} $\alpha = 0$ corresponds to parameter-independent masking
(C3 satisfied). RMSE Ratio = RMSE(Misspecified) / RMSE(Correct); values $< 1$
indicate the misspecified model has \emph{lower} RMSE due to fewer parameters.
\end{minipage}
\end{table}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.9\textwidth]{fig7_c3_misspec_bias.pdf}
\caption{C3 misspecification bias comparison. The misspecified model (ignoring
parameter-dependent masking) shows different bias patterns from the correct
model, but the magnitude of bias grows with $\alpha$.}
\label{fig:c3_misspec_bias}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.8\textwidth]{fig8_c3_rmse_ratio.pdf}
\caption{RMSE ratio (misspecified / correct) for C3 violations. Unlike C2
misspecification (\Cref{fig:rmse_ratio}), the ratio is often below 1,
indicating the simpler misspecified model can achieve lower RMSE despite bias.}
\label{fig:c3_rmse_ratio}
\end{figure}

\subsubsection{Interpretation}

Key findings from Study 4:
\begin{enumerate}
    \item \textbf{Bias grows with $\alpha$:} As the power parameter
        increases, the C1-C2-C3 model produces increasing bias,
        confirming \Cref{thm:misspec-C3}.
    \item \textbf{Bias-variance tradeoff:} The correctly specified relaxed C3
        model often has \emph{higher} RMSE than the misspecified model
        (RMSE ratio $< 1$), because the additional masking parameters
        increase variance. This contrasts with the C2 case (Study 2)
        where RMSE ratios were close to 1.
    \item \textbf{Overfit risk (Scenario 5):} Fitting the relaxed C3 model
        to C1-C2-C3 data produces bias for $\alpha > 0$, with convergence
        rates dropping to 80--98\%, indicating overfitting when the
        extra flexibility is unnecessary.
    \item \textbf{Comparison with C2:} While C2 misspecification
        (Study 2) showed at most 9\% efficiency loss, C3
        misspecification creates a more complex picture with
        parameter-specific effects and a bias-variance tradeoff
        favoring the simpler model in many cases.
\end{enumerate}

\subsection{Study 5: Weibull Series Systems}
\label{sec:sim-weibull}

To assess whether our findings generalize beyond exponential components, we
repeat key analyses with Weibull components. We consider a 2-component system
with shapes $\mathbf{k} = (2.0, 1.5)$ and scales
$\vlambda = (3.0, 4.0)$, using $n = 200$, $\tau = 8$, and $B = 100$
replications.

\subsubsection{Scenarios}

\begin{description}
    \item[W1:] C1-C2-C3 data $\to$ C1-C2-C3 model (baseline).
    \item[W3:] Relaxed C2 data $\to$ C1-C2-C3 model (C2 misspecification).
    \item[W4:] Relaxed C2 data $\to$ relaxed C2 model (correctly specified).
    \item[W6:] Relaxed C3 data $\to$ C1-C2-C3 model (C3 misspecification).
    \item[W7:] Relaxed C3 data $\to$ relaxed C3 model (correctly specified).
\end{description}

\subsubsection{Results}

Table~\ref{tab:weibull_sims} presents the Weibull simulation results.

\begin{table}[htbp]
\centering
\caption{Weibull Simulation Results: Bias and RMSE by Scenario}
\label{tab:weibull_sims}
\begin{tabular}{clcccc}
\toprule
Scenario & Parameter & True & Bias & RMSE & Conv. \\
\midrule
W1 & $k_1$ & 2.0 & $0.007$ & 0.124 & 100\% \\
   & $\lambda_1$ & 3.0 & $-0.016$ & 0.155 & \\
   & $k_2$ & 1.5 & $0.006$ & 0.141 & \\
   & $\lambda_2$ & 4.0 & $0.003$ & 0.376 & \\
\midrule
W3 & $k_1$ & 2.0 & $-0.043$ & 0.147 & 100\% \\
   & $\lambda_1$ & 3.0 & $-0.199$ & 0.241 & \\
   & $k_2$ & 1.5 & $-0.028$ & 0.165 & \\
   & $\lambda_2$ & 4.0 & $0.757$ & 0.982 & \\
\midrule
W4 & $k_1$ & 2.0 & $-0.005$ & 0.152 & 100\% \\
   & $\lambda_1$ & 3.0 & $-0.019$ & 0.162 & \\
   & $k_2$ & 1.5 & $0.010$ & 0.146 & \\
   & $\lambda_2$ & 4.0 & $0.041$ & 0.431 & \\
\midrule
W6 & $k_1$ & 2.0 & $-0.044$ & 0.147 & 100\% \\
   & $\lambda_1$ & 3.0 & $-0.209$ & 0.250 & \\
   & $k_2$ & 1.5 & $-0.032$ & 0.170 & \\
   & $\lambda_2$ & 4.0 & $0.821$ & 1.042 & \\
\midrule
W7 & $k_1$ & 2.0 & $-0.440$ & 0.459 & 100\% \\
   & $\lambda_1$ & 3.0 & $0.146$ & 0.278 & \\
   & $k_2$ & 1.5 & $0.639$ & 0.679 & \\
   & $\lambda_2$ & 4.0 & $-0.405$ & 0.481 & \\
\bottomrule
\end{tabular}

\vspace{2pt}
\begin{minipage}{\textwidth}
\footnotesize
\textit{Notes.} True Weibull parameters: $k_1 = 2.0$, $\lambda_1 = 3.0$,
$k_2 = 1.5$, $\lambda_2 = 4.0$. $P$ matrix: $P_{12} = 0.3$, $P_{21} = 0.5$
for relaxed C2; $\alpha = 1$, base\_p $= 0.5$ for relaxed C3.
\end{minipage}
\end{table}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.7\textwidth]{fig9_weibull_baseline.pdf}
\caption{Weibull baseline MLE performance (W1). Bars show bias, error bars
indicate RMSE. All parameters are estimated with small bias and reasonable
RMSE.}
\label{fig:weibull_baseline}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.9\textwidth]{fig10_weibull_misspec.pdf}
\caption{Weibull misspecification comparison. Left: C2 violation (W3 vs W4).
Right: C3 violation (W6 vs W7). The correctly specified C2 model (W4)
substantially reduces bias; the C3 case is more complex.}
\label{fig:weibull_misspec}
\end{figure}

\subsubsection{Interpretation}

Key findings from Study 5:
\begin{enumerate}
    \item \textbf{Weibull baseline performs well:} Under correctly specified
        C1-C2-C3 (W1), all Weibull parameters are estimated with small bias
        and reasonable RMSE, confirming the MLE framework extends to
        non-exponential components.
    \item \textbf{C2 misspecification hurts:} Ignoring informative masking
        (W3) produces substantial bias in the scale parameter $\lambda_2$
        (bias $= 0.757$), which is largely corrected by the relaxed C2
        model (W4, bias $= 0.041$). This is more pronounced than the
        exponential case, likely because Weibull scale and shape parameters
        interact with the masking weights.
    \item \textbf{C3 misspecification in Weibull:} The misspecified model (W6)
        shows large $\lambda_2$ bias ($0.821$), but the correctly specified
        relaxed C3 model (W7) performs \emph{worse}, with substantial
        bias in the shape parameters ($k_1$: $-0.440$, $k_2$: $0.639$).
        This suggests that parameter-dependent masking is more difficult
        to handle with Weibull components due to the interaction between
        shape and scale in the power weights.
    \item \textbf{Exponential results generalize partially:} The qualitative
        finding that C2 misspecification produces predictable bias that can
        be corrected holds for Weibull systems. The C3 case requires further
        investigation for non-exponential distributions.
\end{enumerate}

\subsection{Summary of Simulation Results}
\label{sec:sim-summary}

Our simulation studies lead to the following conclusions:

\begin{enumerate}
    \item \textbf{MLE performs well:} Under the correctly specified C1-C2-C3
        Bernoulli masking model, the MLE achieves coverage near nominal levels
        and RMSE consistent with asymptotic efficiency (Study 1).

    \item \textbf{C2 misspecification is mild:} Misspecifying C2 (assuming
        non-informative masking when masking is informative) produces at most
        9\% efficiency loss and bias patterns similar to the correct model
        (Study 2).

    \item \textbf{Identifiability is robust:} Even with high correlation
        ($\rho = 0.9$) between candidate set indicators, parameters remain
        identifiable with stable FIM eigenvalues and condition numbers
        (Study 3).

    \item \textbf{C3 misspecification is nuanced:} Ignoring parameter-dependent
        masking (C3 violation) produces increasing bias with the power
        parameter $\alpha$, but the simpler misspecified model can have
        lower RMSE due to a bias-variance tradeoff (Study 4).

    \item \textbf{Weibull systems confirm and extend:} The framework
        generalizes to Weibull components. C2 misspecification produces
        larger bias for Weibull than exponential systems, reinforcing the
        value of relaxed models when masking is known to be informative
        (Study 5).

    \item \textbf{Practical guidance:} For sample sizes $n \geq 100$ with
        moderate masking and censoring, the C1-C2-C3 model provides reliable
        inference. Relaxed models are most beneficial when (a) masking is
        known to be informative, (b) the masking mechanism can be
        characterized, and (c) the sample size supports additional parameters.
\end{enumerate}

\begin{table}[htbp]
\centering
\caption{Summary of key simulation findings across all five studies.}
\label{tab:sim-summary}
\begin{tabular}{lccccc}
\toprule
Metric & Study 1 & Study 2 & Study 3 & Study 4 & Study 5 \\
\midrule
Components & 3 (exp) & 3 (exp) & 3 (exp) & 3 (exp) & 2 (Weibull) \\
RMSE range & 0.20--0.56 & 0.19--0.47 & 0.23--0.47 & 0.15--0.77 & 0.12--1.04 \\
Coverage range & 92--97\% & --- & --- & --- & --- \\
Max RMSE ratio & --- & 1.09 & --- & 1.85 & --- \\
Min FIM eigenvalue & --- & --- & 12.23 & --- & --- \\
\bottomrule
\end{tabular}
\end{table}
